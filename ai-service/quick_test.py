#!/usr/bin/env python3
"""
Test rapide du modÃ¨le LibreScript AI
"""

import gpt_2_simple as gpt2
import tensorflow as tf
import os

MODEL_NAME = "124M"
RUN_NAME = "librescript_code_model"

def quick_test():
    """Test rapide du modÃ¨le"""
    print("ğŸ§ª Test rapide du modÃ¨le LibreScript AI")
    print("=" * 40)
    
    # VÃ©rifier que le modÃ¨le de base existe
    if not os.path.isdir(os.path.join("models", MODEL_NAME)):
        print(f"ğŸ“¥ TÃ©lÃ©chargement du modÃ¨le de base {MODEL_NAME}...")
        gpt2.download_gpt2(model_name=MODEL_NAME)
    
    # VÃ©rifier que le modÃ¨le fine-tunÃ© existe
    checkpoint_dir = os.path.join("checkpoint", RUN_NAME)
    if not os.path.exists(checkpoint_dir):
        print("âŒ Erreur: Aucun modÃ¨le fine-tunÃ© trouvÃ©!")
        print("ğŸ’¡ Vous devez d'abord entraÃ®ner le modÃ¨le avec: python3 ai.py")
        return
    
    print("ğŸ”„ Chargement du modÃ¨le...")
    sess = gpt2.start_tf_sess()
    
    try:
        gpt2.load_gpt2(sess, 
                      model_name=MODEL_NAME,
                      run_name=RUN_NAME)
        print("âœ… ModÃ¨le chargÃ© avec succÃ¨s!")
        
        # Tests avec diffÃ©rents prompts
        test_prompts = [
            "# Question: How to create a function in Python?",
            "# Content: I need help with JavaScript",
            "Comment faire une boucle en Python",
            "SQL query example"
        ]
        
        for i, prompt in enumerate(test_prompts, 1):
            print(f"\nğŸ§ª Test {i}/4: {prompt}")
            print("-" * 50)
            
            try:
                generated = gpt2.generate(sess,
                                        run_name=RUN_NAME,
                                        length=100,
                                        temperature=0.8,
                                        prefix=prompt,
                                        nsamples=1,
                                        batch_size=1,
                                        return_as_list=True)
                
                if generated and len(generated) > 0:
                    response = generated[0]
                    if response.startswith(prompt):
                        response = response[len(prompt):].strip()
                    print(f"ğŸ¤– RÃ©ponse: {response[:200]}...")
                else:
                    print("âŒ Aucune rÃ©ponse gÃ©nÃ©rÃ©e")
                    
            except Exception as e:
                print(f"âŒ Erreur: {e}")
        
        print(f"\nâœ… Test terminÃ©! Le modÃ¨le fonctionne.")
        print("ğŸ’¡ Utilisez 'python3 prompt.py' pour l'interface interactive")
        
    except Exception as e:
        print(f"âŒ Erreur lors du chargement: {e}")

if __name__ == "__main__":
    quick_test() 